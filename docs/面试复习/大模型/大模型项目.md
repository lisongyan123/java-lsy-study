# markdown
模型层和服务化都是 python, CANN 层改改算子, 模型层接入一下融合算子, 服务化适配一下接口跑起来

## 大模型产品理解

1. 烧钱送 token 换用户的大模型
    1. 第一类, 好的用户体验为基础, 成为用户工作、生活中的工具, 能积累下他们的过程资产, 方能有沉没成本勾住用户留下来。但现状是,
       用户上传了图片、文本后, 想搜索找历史资料可太难了。还不如用聊天工具的 AI 机器人插件, 能很好的管理过程资产, 一搜就好了,
       还按时间线类别把资料归档
2. 过滤信源做纯净版 RAG 搜索的大模型(AI搜索 如Perplexity、You.com、exa.ai、秘搭等)
    1. 第二类, 信源过滤会损害未来的广告收入, 如何让营销内容出现在用户 RAG 的内容中。 要规模, 还是要付费用户？前期养成这么高的期望,
       付费后要更进步提供怎么样的增值服务, 不然一收费用户就去下一家免费的竞品
3. 不展示提示词原创来源的智能体社区
    1. 第三类, GPTs 已经验证了无原创保护对创作者的积极性伤害。提示词攻击套取系统提示词, 然后克隆一个一样的智能体,
       在私域里推广。由于抄袭者不用花时间精力进行创作, 能更好的去进行推广和社群运营。最终会导致原创作者的积极性受到损害,
       继续发展下去, 由于各社区互抄, 差异性被拉平, 竞争力也会被削弱

Agent方向: 比如电商锁库补仓, 工厂检测流程, 或者其他有实际业务流, 结合业务场景是一方面, 另一方面, 封装好体验优良的产品和工具,
让业务人员方便配置操作,

你以前做个程序, 要执行起来不是有关键字触发, 就是要有特定条件才执行。现在的 agent 因为大模型要比以前智能多了,受限于基座模型能力
泛化能力更强, 也能执行更复杂的命令。不过现在有个幻觉还没解决, 也不敢执行高危操作。例如你让模型执行“给我删掉xxx表里的xxx数据。”
万一生成一个错误 sql 去执行了。

唯一有用的是大模型帮忙优化了一下用户的搜索语句,
当消费者无条件信任平台的情况下, 没人去深究生成结果与搜索结果是否相关, 但凡杠精一下就会发现, 生成结果和搜索结果相关性不高,
生成质量与搜索质量也没太大关系,
如果设置 5 个选项让它选好坏, 会优先选择排序第一或最末的选项, 它实质上并不具备直接判断好坏的能力
隐私以及数据实时更新等问题, 给出最新时间和文章时间, 模型区分内容中哪些事实的过时的, 哪些是最新的也挺困难。
隐私性如果训练前语料没清洗, 通过中间补全的方法, 大概率还是能把秘密套出来

垂直领域的大模型得有数据, 中医领域不是没有数据, 只是数据必须是标准化的, 而中医数据的标准化需要建立在中医业务的标准化之上,
由于幻觉问题, 必然会出现误诊, 那时候中医从业人员必定群起而攻之, 这是人性算法、业务、商业、人性一大堆东西都懂

很多垂直领域的数据出于商业机密、隐私、国家安全等原因不可能对大模型开放, 这类垂直领域的大模型还是会保留的, 中医资料核心的都是闭源的,
真正有好的知识, 都是师承经验, 口授传承、半保密状态的教学课件

数据比模型重要, 只要有知识库, 搞个搜索推荐系统, 中医的量化数据太难归纳, 不像西医有 his 系统

法律大模型, 至少条文判例是公开的

# 小公司大模型现状

2. 上家我们算法团队人均一台 gpu 服务器, p100 和 v100 集群可以用, 显卡环境现成的, 各种环境镜像包现成的。现在换了家小公司,
   一个 gpu 服务器申请了几个月被否了
3. 小公司算力不够, 数据一团糟, 数据套 gpt, 显卡没几张微调只能 loRA 能怎么样, 6 台 a40*4都不够用?
4. 少 1w 台以上 a100 或者同类型机器才能训练大模型
5. 配置一台 3090 双卡 48g, 一台 3060 24g, 只能跑跑 qwen-14b, 只能推理, 训练不够
9. 这种行业大模型全参微调, 得搞个 8 卡服务器, 200 万, 准备十万个人工标注过得问答对, 发布会时前面加个知识库就好, 知识库+rag+行业大模型, 低成本就这么搞最多两个月
15. 大模型成本高, 可以 RAG, 先放下微调和精调, 大模型只做话术总结和意图识别, 具体任务还是由小模型解决
16. 对内的话用 langchain 或者 lammaindex (LLaMA index, LLaMA 的 langchain), 结合图谱和知识查询, 已经验证过有效, 有条件的还是得微调, 中小公司的数据只精调
17. 开源模型用 qwen14b 支持中文字符
18. 面大模型基本等于面业务, 大部分要的是 nlp 和搜广推经验, 国内的基座快凉透了
19. 一方面 7-13b 左右的模型推理上确实不尽如人意, 用大参数模型项目成本就上去了, 剩下只能组织语料微调, 大模型选的一般都是垂直领域的赛道
21. 怎么做? prompt engineer, prompt 的 evaluate (评估)确实是一个很难的技术课题, 我们的做法是人工 + llm /hard code, 先用
    llm 初筛, 再人工评估,没有很多用户测评, 通过 prompt 进行数据增强, 但是需要对生成的数据进行质量评测。会用 4 筛一遍, 再人工抽查看一遍, 机评+人评
22. 我这边的评测主要还是靠用户反馈的数据, 靠采纳率指标, 人工质检的主观成分较多, 正确清晰的表达诉求对于 prompt 撰写和之后的人工 check 认同和理解的标准
27. 而每个行业都需要自己的模型。学一些其他知识, 把模型的知识放进小模型才是正道
28. 数据或者内容团队, 比如大模型你要标注, 要测评, 这些要么协同产技一起帮你搞, 要么就是找外包, 训练让外包做, 重点是洗数据, 这一块就够你沟通协同的了,
    对齐数据和评测标准, 来回对焦, 最后拉齐标准
29. 我司接的 GPT4.0 和 Google Gemini , 幻觉太严重, 基本 cover 不了场景 claude(学术之神, 代码会debug), gpt(情绪价值), gimini
31. 快消、法律都有做过, rag/继续预训练/微调/rl对齐...面向落地就是哪个好用就用哪个
32. 语言用 deepseek2.5, 多模态用 qwen2vl, 国内 deepseek 和 qwen 比较强, 但是 qwen 数据污染有点严重, 国外claude, gpt,
    llama 都行, 当然龙头老大还是 openai
33. qwen2-72B 的你只是没有机会用到, 这种是需要自己搭建的, qwen2.5 都出来了, 更牛逼, 只是普通人用不到, 有技术壁垒
36. 评估、打标眼睛都要瞎了, 大部分产品经历


