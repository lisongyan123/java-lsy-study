# HashMap

## hashmap的设计

链表长度超过8, 桶数组长度小于64, 先扩容, 然后转红黑树, 退回链表就是小于6

- 初始容量: 默认容量 16, 负载因子 0.75, 12 个槽都占满才会 rehash
- 为什么是 8:  为了扩容和均匀分配, 在负载因子 0.75 条件下, 出现某一链长度为 8 的概率很低, 符合泊松分布
- 为什么负载因子是 0.75:  提高空间利用率和减少查询成本的折中, 0.75 的话碰撞最小。0.75 的时候, 空间利用率比较高, 而且避免了相当多的
  hash 冲突, 使得底层的链表或者是红黑树的高度比较低, 提升了空间效率。负载 0.5 的话树高度低空间利用率高了。如果是 hash 冲突很多
  rehash 的解释: 在创建 hashmap 的时候可以设置来个参数, 默认初始化容量创建 hash 表时桶的数量。当 hash 表中的负载因子达到负载极限的时候,
  hash表会自动成倍的增加容量(桶的数量), 并将原有的对象重新的分配并加入新的桶内, 这称为 rehash
- 1.7 到 1.8 头插法变尾插法, 假如多线程对一个 entry 进行 put 操作, 扩容后链表反转, 不用获取最后一个元素直接出来, 导致
  A->B 变为 B->A, 保证 put 安全但是修改还是不安全

## hashmap 为什么会线程不安全

- 在 put 方法中判断是否出现 hash 碰撞, 两个线程 A、B 都在进行 put 操作, 并且 hash 函数计算出的插入下标是相同的, A直接进行插入,
  这就导致了线程 B 插入的数据被线程 A 覆盖了, 从而线程不安全
- 还有个 ++size, 线程A、B, 这两个线程同时进行 put 操作时, AB线程并发执行可能只增加了1

## 为什么要重写 hashCode和 equals

- 存入 k1 的时候, 会调用 Object 类的 hashcode 方法, 计算它的 hash 值,获取对象的地址, 随后把 k1 放入 hash 值所指引的内存位置,
  而 Object 类的 hashcode 方法返回的 hash 值是。由于 k1 和 k2 的内存地址是不一样的, 所以用 k2 拿不到 k1 的值

- 重写 hashcode 方法仅仅能够 k1 和 k2 计算得到的 hash 值相同, 调用 get 方法的时候会到正确的位置去找, 但当出现散列冲突时,
  在同一个位置有可能用链表的形式存放冲突元素, 需要用到 equals 方法去对比了, 由于没有重写 equals 方法,
  它会调用 Object 类的 equals 方法, Object 的 equals 方法判断的是两个对象的内存地址是不是一样, 由于 k1 和 k2 都是 new
  出来的,
  k1 和 k2 的内存地址不相同, 所以这时候用 k2 还是达不到 k1 的值

# CurrentHashmap

**CurrentHashMap的设计**
Node 数组长度默认是 16, ode 和 val 是用 volatile 来修饰的, 在数组扩容时表现可见性, 类比于 hash

**put 操作**

1. 第一次 put 的时候 table 没有初始化, 则初始化 table
2. 通过哈希计算出表中位置, 因为 n 是数组长度, 这个位置如果没有元素, 用 cas 尝试添加 Node 节点。
3. 如果某节点 hash 值是 MOVED, 表示正在数组扩张, 当前线程参与复制, 减少数组复制带来的损失。
4. 如果这位置有元素, 那就是冲突, synchronized 加锁, 链表的话就遍历找一样的 key, 值替换(为什么不用cas, 因为有值后值不固定代码不能写死,
   cas是固定为null)

**size** baseCounts 是 voletile 类型,用 cas 操作保证并发安全

**扩容的时候可以读吗** 当在进行数组扩容的时候, 如果当前节点还没有被处理, 则当前线程也会加入到扩容的操作中去

**Vector** 读写用了 Synchronized 同步

# CopyOnWriteArrayList

- 写操作在一个复制的数组上进行, 读操作还是在原始数组中进行, 读写分离, 互不影响
- 写操作需要加锁, 防止并发写入时导致写入数据丢失
- 写操作结束之后需要把原始数组指向新的复制数组

## 缺陷

1. 内存占用: 在写操作时需要复制一个新的数组, 使得内存占用为原来的两倍左右
2. 数据不一致作不能读取实时性的数据, 因为部分写操作的数据还未同步到读数组中

## volatile

声明的变量, 更新的时候对其他线程可见, 使用内存屏障保证不会发生指令重排, 解决内存可见性问题  
不保证原子性, 变量被 volatile 修饰后, AB 线程对变量 X 更改后, 会更新到主内存加载最新的值到工作内存,
写操作会导致其他线程中的缓存无效, 任意操作都可能被其他线程干扰

### 为啥重排序

编译器对指令重排序对 cpu 运行效率友好, volatile 在 jvm 里的实现往往基于 load
store 禁止编译器对 barrier 前后的读写重排序, 可见性是缓存一致性的前提

## 深拷贝, 浅拷贝

浅拷贝只复制内存地址, 新旧对象还是共享同一块内存(分支)

## ThreadLocal

Thread 中维护一个 Map, 记录 ThreadLocal 与实例之间的映射关系, 线程隔离

ThreadLocalMap 的 key 是 WeakReference, 如果 key 都是强引用, 当 ThreadLocal 不再使用时, 然而 ThreadLocalMap 中还是存在对
ThreadLocal 的强引用, 那么 GC 是无法回收的, 从而造成内存泄漏

----
**hash冲突的解决**

1. nextHashCode 是 AtomicInteger 类型, 通过线程安全的方式来加减, 保证 hashCode 可以均匀的分布在 2 的 n 次方数组里,
   尽量避免冲突
2. set 线性探测法: 的时候用线性探测法探测下一个地址, 如果找到空的地址就插入, 如果没有空余地址, 就溢出, 需要 O(n)
   时间复杂度解决冲突问题, 效率较低

# 线程池(ThreadPoolExecutor)

1. 核心线程数 (corePoolSize): 线程池中保持的核心线程数, 即使它们处于空闲状态也不会被销毁
1. 最大线程数 (maximumPoolSize): 线程池中允许的最大线程数
1. 空闲线程存活时间 (keepAliveTime): 线程池中的非核心线程在空闲一段时间后会被销毁, 非核心线程等待被回收时间,
   当线程池中的非核心线程在执行完任务后处于空闲状态超过这个时间时将被终止
1. 任务队列 (workQueue): 用于存储待处理任务的阻塞队列
1. 拒绝策略 (RejectedExecutionHandler): 当线程池无法接受新任务时的处理策略, 常见的拒绝策略包括
    1. AbortPolicy: 抛出 RejectedExecutionException 异常
    1. CallerRunsPolicy: 由调用者线程执行任务
    1. DiscardPolicy: 直接丢弃任务
    1. DiscardOldestPolicy: 丢弃队列中最老的任务, 然后重新提交被拒绝的任务

# 线程池异常问题

‌线程池中线程异常后, 通常不会销毁线程, 而是会进行复用。‌线程池中的线程是预先创建并管理的, 其生命周期通常与整个线程池的生命周期相关,
当线程在执行任务时抛出异常, 线程本身并不会因为异常而被“销毁”, 而是会继续等待下一个任务或被复用‌

异常处理策略
‌重新提交任务‌：在某些情况下, 可以捕获异常并在适当的时候重新提交任务。然而, 这需要谨慎处理, 以避免任务被无限期地重新提交‌1。
‌使用UncaughtExceptionHandler‌：Java的Thread类提供了一个setUncaughtExceptionHandler方法, 允许设置一个处理器来处理未捕获的异常。在线程池中, 可以为每个线程设置这样的处理器, 以便在异常发生时执行自定义的逻辑(例如, 记录异常、发送警报等)

## 线程内部状态

1. running: 对应核心线程数, 接收新任务, 处理阻塞队列的任务, 如果不手动调用关闭方法, 那么线程池在整个程序运行期间都是此状态
2. shutdown: 不接收任务, 将已保存在任务队列中的任务处理完
3. stop:  不接受任务, 不处理阻塞队列的任务, 线程池状态变为stop, 中断工作和空闲线程, 丢弃工作队列中存量任务
4. tidying:  线程池任务为空,整理状态, 所有的任务都执行完毕后, terminated()
5. terminated:  销毁状态, 当执行完线程池的 terminated() 方法之后就会变为此状态

![线程池状态.png](线程池状态.png)

## Tomcat 线程池

IO 密集型, 期望任务堆积时, 优先创建线程来处理, 而不是入队, 线程数增加时候, jdk 是入队, tomcat 是创建新的线程执行任务

# Synchronized锁 :

## 锁升级

1. 无锁: 现场没获取 Synchronized 锁的状态
2. 偏向锁: 即偏向第一个拿到锁的线程, 锁会在对象头的 Mark Word 通过 CAS(Compare And Swap)记录获得锁的线程id, 同时将Mark
   Word 里的锁状态置为偏向锁, 是否为偏向锁的位置为 1,
   当下一次还是这个线程获取锁时就不需要通过 CAS。如果其他的线程尝试通过 CAS 获取锁(即想将对象头的 Mark Word 中的线程 ID
   改成自己的) 会获取失败, 此时锁由偏向锁升级为轻量级锁
3. 轻量级锁: JVM 会给线程的栈帧中创建一个锁记录(Lock Record)的空间, 将对象头的 Mark Word 拷贝到 Lock Record 中,
   并尝试通过 CAS 把原对象头的 Mark Word 中指向锁记录的指针指向当前线程中的锁记录, 如果成功, 表示线程拿到了锁。如果失败,
   则进行自旋(自旋锁), 自旋超过一定次数(10次)时升级为重量级锁, 这时该线程会被内核挂起
4. 自旋锁: 轻量级锁升级为重量级锁之前, 线程执行 monitor enter 指令进入 Monitor 对象的 EntryList 队列, 此时会通过自旋尝试获得锁,
   如果自旋次数超过了一定阈值(默认10), 才会升级为重量级锁, 等待线程被唤起。线程等待唤起的过程涉及到 Linux 系统用户态和内核态的切换,
   这个过程是很消耗资源的, 自选锁的引入正是为了解决这个问题
5. 重量级锁

----

## 锁降级

写线程获取写入锁后可以获取读取锁, 然后释放写入锁, 这样就从写入锁变成了读取锁, 从而实现锁降级的特征, 保证数据的可见性

**为什么降级**

1. 为了保证数据可见性。假设线程A修改了数据, 释放了写锁, 这个时候线程T获得了写锁, 修改了数据, 然后也释放了写锁,
   线程A读取数据的时候, 读到的是线程T修改的, 因此通过锁降级来保证数据每次修改后的可见性
3. 比如 AB 线程改一个数据 i, 依次+1, Thread-0 释放了写锁后, 由于 Thread-0 还拥有着读锁, Thread-1 并不能获取写锁篡改 i
   的值, 保证了 i 的值修改后的可见性

synchronized(排他锁):  在对象头设置标记实现

+ Monitor: EntryList + Owner + WaitSet 组成
+ EntryList: 当多个线程同时访问一个 Monitor 对象时, 这些线程会先被放进 EntryList 队列, 此时这些线程处于Blocked状态,
+ Owner: 当一个线程获取到了这个 Monitor 对象时, Owner 会指向这个线程, 当线程释放掉 Monitor 对象时, Owner 会置为null,
+ WaitSet: wait 方法时, 当前线程会释放对象锁, 同时该线程进入 WaitSet 队列, Monitor 对象还有一个计数器 count 的概念,
  这个 count 是属于 Monitor 对象的, 当 Monitor 对象被某个线程获取时, ++count, 当 Monitor 对象被某个线程释放时, --count

## 非公平

1. 更高的吞吐量:
1. 减少上下文切换: 非公平锁允许刚释放锁的线程立即重新获取锁, 而不需要将 CPU 让给其他等待的线程。这减少了不必要的上下文切换, 从而提高了系统的整体吞吐量。
1. 更少的饥饿问题: 由于非公平锁不会严格遵循排队顺序, 因此可以更快地响应那些刚刚开始尝试获取锁的线程, 这有助于降低某些线程长时间得不到执行的机会, 即减少“饥饿”现象

# 为什么有泛型擦除

编译时, 避免使用强制类型转换。全都统一成 Object 类, 主要是为了兼容以前的工具类

# 单链表和双链表:

双链表添加和删除很快, 也可以用二分法提高查询效率, 但是单链表使用的场景比较多
因为单链表从存储结构来看, 每个双链表的节点要比单链表的节点多一个指针, 而长度为 n 就需要 n*length
的空间, 这在一些追求时间效率不高应用下并不适应, 因为它占用空间大于单链表所占用的空间

# Lock 和 Synchronized 区别:

|     | synchronized                     |                                             而lock                                             |
|:---:|:---------------------------------|:---------------------------------------------------------------------------------------------:|
| 加锁类 | 类, 方法, 代码块                       |                                              代码块                                              |
| 自动性 | 不需要手动获取锁和释放锁, 发生异常会自动释放锁, 不会造成死锁 |                          需要手动自己加锁和释放锁, 如果使用不当没有 unLock 去释放锁, 就会造成死锁。                          |
|     | 无锁、偏向锁、自旋锁、向OS申请重量级锁             |                               不需要手动获取锁和释放锁, 发生异常会自动释放锁, 不会造成死锁                                | 需要手动自己加锁和释放锁, 如果使用不当没有 unLock 去释放锁, 就会造成死锁 |
| 类型  | 同步阻塞, 采用的是悲观并发策略                 |                          需要手动自己加锁和释放锁, 如果使用不当没有 unLock 去释放锁, 就会造成死锁。                          |
| 自动性 | 不需要手动获取锁和释放锁, 发生异常会自动释放锁, 不会造成死锁 | 需要手动自己加锁和释放锁, 如果使用不当没有 unLock 去释放锁, 就会造成死锁。通过wait()/notify()/notifyAll()方法要么随机唤醒一个线程要么唤醒全部线程。 |

# 线程状态

+ NEW(初始), 新建状态, 线程被创建出来, 但尚未启动时的线程状态
+ RUNNABLE(就绪状态), 表示可以运行的线程状态, 它可能正在运行, 或者是在排队等待操作系统给它分配 CPU 资源
+ BLOCKED(阻塞), 阻塞等待锁的线程状态, 表示处于阻塞状态的线程正在等待监视器锁, 比如等待执行 synchronized 代码块或者使用
  synchronized 标记的方法
+ WAITING(等待), 等待状态, 一个处于等待状态的线程正在等待另一个线程执行某个特定的动作, 比如, 一个线程调用了
  Object.wait()方法, 那它就在等待另一个线程调用 Object.notify() 或
  Object.notifyAll()方法
+ TIMED_WAITING(超时等待): 不同于WAITING,无需等待其它线程显式地唤醒, 在一定时间之后会被系统自动唤醒
+ TERMINATED, 终止状态, 表示线程已经执行完成
+ 等待队列: wait 进入等待队列, notifyAll 唤醒所有线程, 所有线程进入锁池, 锁池里面放的都是想争夺对象锁的线程

# 阻塞队列:

ArrayBlockingQueue
> 1. 数组阻塞队列, 这个队列是一个有界队列, 遵循FIFO, 尾部插入, 头部获取
> 2. 初始化时需指定队列的容量 capacity
> 3. 类比到上面的场景, 就是椅子的数量为初始容量capacity
----
LinkedBlockingQueue
> 1. 链表阻塞队列, 这是一个无界队列, 遵循FIFO, 尾部插入, 头部获取
> 2. 初始化时可不指定容量, 此时默认的容量为Integer.MAX_VALUE, 基本上相当于无界了, 此时队列可一直插入(如果处理任务的速度小于插入的速度,
     时间长了就有可能导致OOM)
> 3. 类比到上面的场景, 就是椅子的数量为Integer.MAX_VALUE

SynchronousQueue
> 1. 同步队列, 阻塞队列的特殊版, 即没有容量的阻塞队列, 随进随出, 不做停留
> 2. 类比到上面的场景, 就是椅子的数量为0, 来一个人就去柜台办理, 如果柜台满了, 就拒绝

PriorityBlockingQueue
> 1. 优先级阻塞队列, 这是一个无界队列, 不遵循FIFO, 而是根据任务自身的优先级顺序来执行
> 2. 初始化可不指定容量, 默认11(既然有容量, 怎么还是无界的呢？因为它添加元素时会进行扩容)
> 3. 类比到上面的场景, 就是新来的可以插队办理业务, 好比各种会员

DelayQueue
> 1. 基于优先队列, 最小堆结构, 队首元素是最先到期元素, 取出元素如果到期就可以取出
> 2. 调度线程: 通常会有一个或多个线程不断检查队列中的元素是否已经到期, 一旦发现到期的元素就会将其取出并处理
> 3. Leader/Followers模式: 只有当前领导线程（Leader）会等待到期的元素, 其他线程（Followers）处于等待状态。当领导线程唤醒时,
     它会选出一个新的领导线程, 自己则去处理到期的元素

# AtomicInteger 的原理

i++非线程安全, 原理是 cas + volatile

# 线程之间通信:

1. 工作中涉及到并发, 如果是业务开发, 用线程池实现并发, 用框架开发的话采用单个线程, 单线程负责一个流程中部分功能,
   多线程紧密配合, 子线程抛异常, 主线程无法捕获
2. 比如 RocketMQ, 引入阻塞队列(线程安全), 充当任务队列, PullMessageService 从阻塞队列获取消息, 如果没有任务就阻塞等待,
   非常关键, 避免空轮询造成 CPU 飙升, RebalanceService 根据任务负载均衡生成任务, 放入任务队列, 唤醒 PullMessageService
3. 中断线程有两种方法 Thread.interrupted() 和 this.stoped, stoped 会使用 volatile 关键字首饰, 如果要停止该线程,
   并且需要暴露一个方法,
   用于将 stoped 设置为 true,从而跳出循环, 注意 while 从队列获取待执行任务的时候, 没有任务执行就阻塞当前线程, 避免消耗
   CPU
4. 如果生产者线程 RebalanceService 出现异常停止, PullMessageService 线程由于一直没有获取任务而阻塞, 捕获消费者线程的异常,
   一场包装类放到任务队列, 判断任务类型来通知下游服务

### 单例模式:

```java
        //双重校验锁+懒汉式
public class DoubleCheckSingleton {
    private DoubleCheckSingleton() {
    }

    private volatile static DoubleCheckSingleton instance;

    public static DoubleCheckSingleton getInstance() {
        if (instance == null) {
            synchronized (DoubleCheckSingleton.class) {
                if (instance == null) {
                    return new DoubleCheckSingleton();
                }
            }
        }
        return instance;
    }
}
```

----

```java
    //饿汉式实现单例模式
public class Hungry {

    private Hungry() {
    }

    private static Hungry hungry = new Hungry();

    public static Hungry getHungry() {
        return hungry;
    }
}
```

# 问题

1. OOM、死锁、超时问题可以再运维层面改配置、重启、扩容等手段解决
2. 缓存击穿、多线程环境使用非线程安全的类, 在多线程高并发情况才会暴漏问题
3. 性能问题不会导致明显的 bug, 让程序运行缓慢、内存使用增加, 量变到质变瞬间爆发

# 常见 bug

## MQ

业务处理失败的消息不断进入 MQ, 结束后还需要花费很长时间补充正常的业务数据, 一定要针对队列积压做好监控报警

## 存储

使用 SaaS 存储, 比如 OSS, 上传走的内部服务器, 流量一起来, 自家的流量被占满, 全线崩溃, 要么全走云, 要么全走本地

## spring 配置注入 bean, 配置缺省(系统默认状态)

单线程测试正常, 多线程各种异常, 默认的 bean 是单例的, 多线程调用线程不安全

## 线程池

Executors 线程池工具类的几种创建线程池的方法, 都不适合在生产高并发场景下使用

# 项目规范

Springboot 的 controller service 和 mapper 尽可能保持无状态, 锁的粒度缩小, 性能无法满足的话就可以通过区分读写锁,
资源冲突采用悲观锁和乐观锁方式解决

## 超时自动释放避免重复

1. 避免超时, 锁续期, 如 redission 的 watchdog, 单独开一个线程给锁延长有效期, 设置锁有效期 30s,线程每 10s 重新设置下有效期
2. 避免重复, 增加标记表示字段是否被处理, 或者开新的表保存处理过的流水号
    1. 场景是, A和B 买可乐和雪碧遇到死锁, 10s后锁释放了, B买雪碧, 但同时 C 获取了可乐锁, 被重复购买

# 连接池

![](.java业务的坑_images/99e267c3.png)

1. jedis: 池和连接分离
2. httpclient: 内置连接池 API

最大连接数最重要, 最大连接数不够导致性能问题, 但不是越大越好

# 超时、重试、并发

1. 连接超时参数 ConnectTimeout: 设置 1-5s, 内网的话参数可以更短, 下游服务离线无法连接快速失败, 让用户配置建立连接阶段最长等待时间,
   不必设置太长, tcp 三握四挥时间很短, 几秒连不上可能永远连不上
   排查问题可以从 Nginx 的反向代理和负载均衡
2. 读取超时参数 ReadTimeout: 控制用户从 Socket 读取数据的最长等待时间

## 误区

1. 认为读超时服务端执行中断, 只要传到了服务端, 网络断了也不影响执行
2. 认为读取超时只是 Socket 网络层面的概念, 传输数据最长耗时, 配置的很短比如 100 ms, socket 写入到返回这段时间,
   包括网络传输时间 + 服务端业务处理时间
3. 认为超时时间越长任务接口成功率就越高, 将读取超时参数配置得太长, 并发量较大就配置一个较短的读取超时时间, 防止被下游服务拖慢,
   不超过 30s, 定时或者异步任务无所谓, 根据下游服务 SLA, 为不同服务端接口设置不同的客户端读取超时

# spring 的事务

## @Transactional 生效原则

1. public 方法生效, spring 默认通过动态代理方式实现 private 无法被动态代理到
2. 必须通过代理过的类从外部调用目标方法才能生效

# 序列化

1. RedisTemplate: 使用 JDK 序列化
2. StringRedisTemplate: 使用 string 序列化

# Spring

1. 父类如果有状态会产生内存泄露或者线程安全的问题
2. 解决: 设置生命周期多例 @Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)

# 安全问题

1. 使用 IP 定位不准确, 网吧、学校、公司等机构的出口 IP 是同一个, 最好的是用微信第三方授权登录去做一个唯一性判断
2. 每一个需要登陆的方法, 从 session 获得用户标识
3. 使用开放的、面向用户的平台资源要考虑防刷, 主要包括正常使用流程识别、人机识别、单人限量和全局限量等手段
4. 后端幂等控制, 根据 token, 客户端的序列号, 有意义的业务订单号
5. 根据幂等依据进行防重处理
    1. 限制: 锁方式
    2. 去重方式
6. 监控报警, 做好报警阈值处理
7. 先有订单再有资金操作
8. 短信防刷
    1. 固定请求头才能发验证码, 爬虫只能抓取 URL, 很难分析额外请求头
    2. 注册页面才能发送验证码
    3. 相同手机号发送次数和频次

# 注入攻击

1. 客户端给服务端的查询值, 注入数据成为 SQL 一部分叫做 SQL 注入, cookie 也可以
2. 规则引擎会用动态语言做一些计算, 和 SQL 注入一样外部传入的数据只能当作数据使用, 叫代码注入
3. 用户注册、留言、评论等功能服务端从客户端收集信息, 替换了 javascript 代码, 服务端可能将此类代码保存到数据库, 叫 XSS 攻击

## 打印 SQL 语句

<groupId>com.github.gavlyukovskiy</groupId>

