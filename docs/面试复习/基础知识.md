# 排查思路

1. 查看 cpu 和内存使用率, cpu使用率很低, 5%左右, 内存使用一直不变, 基本排除不是他们的问题。
2. gc: full gc没有发生, young gc 虽然增加了一点, 但是平均响应时间也就是50ms, 正常
3. dump内存: 下了一个 126M 的 dump 包, 有一个类占了60m, 首先怀疑是不是内存溢出了, 但是通过分析, 这部分缓存是必需要做的
4. 发现有很多 ForkJoinPool.commonPool-worker-线程正在等待, 生产服务器电脑核数较小, 而在CompletableFuture代码中又使用了默认的线程池,
   处理的线程个数是电脑核数1。这样等有大请求量过来, 处理逻辑又很复杂, 很多线程都在等待执行, 慢慢拖垮了服务器
5. 最后用自带的 excutor 线程数执行

# LSM树

1. MemTable: 是在内存中的数据结构, 用于保存最近更新的数据, 会按照Key有序地组织这些数据, LSM树对于具体如何组织有序地组织数据并没有明确的数据结构定义,
   例如 Hbase 使跳跃表来保证内存中 key 的有序。因为数据暂时保存在内存中, 内存并不是可靠存储, 如果断电会丢失数据, 因此通常会通过
   WAL(Write-ahead logging, 预写式日志)的方式来保证数据的可靠性
2. Immutable MemTable: 当 MemTable达到一定大小后, 会转化成Immutable MemTable。Immutable
   MemTable是将转MemTable变为SSTable的一种中间状态。写操作由新的MemTable处理, 在转存过程中不阻塞数据更新操作。
3. SSTable: 有序键值对集合, 是LSM树组在磁盘中的数据结构。为了加快SSTable的读取, 可以通过建立key的索引以及布隆过滤器来加快key的查找。
4. 当MemTable达到一定大小flush到持久化存储变成SSTable后, 在不同的SSTable中, 可能存在相同Key的记录,
   当然最新的那条记录才是准确的。这样设计的虽然大大提高了写性能, 但同时也会带来一些问题：
    1. 冗余存储, 对于某个key, 实际上除了最新的那条记录外, 其他的记录都是冗余无用的,
       但是仍然占用了存储空间。因此需要进行Compact操作(合并多个SSTable)来清除冗余的记录。
    2. 读取时需要从最新的倒着查询, 直到找到某个key的记录。最坏情况需要查询完所有的SSTable, 这里可以通过前面提到的索引/布隆过滤器来优化查找速度。

ClickHouse 中的 MergeTree 也是 LSM 树的思想, Log-Structured 还可以联想到 kafka 的存储方式, 树上内存, 树外落盘

# GEOhash

将整个地图或者某个分割所得的区域进行一次划分, 采用 base32 编码方式, Geohash 每个字母或者数字由 5 bits 组成, 5 bits 有
32种不同组合, 将整个地图分为 32 个区域, 00000 - 11111 标识

# quad tree 空间索引四叉树

1. 二维空间的运用
2. 三维空间八叉树

# 列式存储

机械硬盘的磁头无法跳跃, 逻辑上看起来是位置跳跃, 实际上磁头是全部扫过去的, 指针只能磁盘顺序读

# 多副本复制

1. 全同步复制: 追求一致性、牺牲了可用性
2. 半同步复制: 有一个写请求、一个副本接受数据后, 返回成功, 数据一致性、可用性实现了平衡和取舍
3. 异步复制: 主收到写请求后, 及时返回给 client, 异步将请求转发给各个副本, 可用性最高
4. 去中心化复制: n 副本节点集群中, 任意节点可以接受写请求, 一个成功的写需要 w 个节点确认, 读取必须查找 r 个节点,
   根据业务敏感性设置 w/r 参数
    1. 比如 n 是3, 可以设置 w/r 为 2, 读两个节点的时候, 必有一个节点含有最近写入的值
    2. 降低运维复杂度, 可用性高
    3. 导致业务写入冲突
       ![](../.基础知识_images/9e071c10.png)

# 计算机端口

计算机端口范围是 0 ~ 65535, 主要分成三大类

1. 公认端口(0 ~ 1023)
2. 注册端口(1024 ~ 49151)
3. 动态或私有端口(49152 ~ 65535)  
   业界确认比较安全的端口基本上只有 80、8080、443、14000 这几个, 如果开发一个外网服务, 我们应当尽量选用这几个端口来对外进行暴露,
   确保可连通性

# 正则表达式写的不好, 会存在回溯的行为

# 进程和线程

## 多进程的优点

1. 编程相对容易: 通常不需要考虑锁和同步资源的问题
2. 更强的容错性: 比起多线程的一个好处是一个进程崩溃了不会影响其他进程
3. 有内核保证的隔离: 数据和错误隔离

## 多线程的优点

1. 创建速度快, 方便高效的数据共享, 共享数据
2. 多线程间可以共享同一虚拟地址空间, 多进程间的数据共享就需要用到共享内存、信号量等 IPC 技术
3. 提供非均质的服务, 如果全都是计算任务, 每个任务的耗时不都为 1s, 而是 1ms-1s 之间波动, 多线程相比多进程的优势就体现出来

## 应用场景

### 多进程应用场景

1. nginx 主流的工作模式是多进程模式(也支持多线程模型)
2. 几乎所有的 web server 服务器服务都有多进程的, 至少有一个守护进程配合一个 worker 进程, 例如 apached,httpd 等等
3. chrome 浏览器也是多进程方式
4. redis 也可以归类到 "多进程单线程" 模型平时工作是单个进程, 涉及到耗时操作如持久化或 aof 重写时会用到多个进程(
   6.0版本改为多线程)

### 多线程应用场景

1. 线程间有数据共享, 并且数据是需要修改的(不同任务间需要大量共享数据或频繁通信时)
2. 提供非均质的服务(有优先级任务处理)事件响应有优先级
3. 单任务并行计算, 在非 CPU Bound 的场景下提高响应速度, 降低时延
4. 与人有 IO 交互的应用, 良好的用户体验(键盘鼠标的输入, 立刻响应), 桌面软件, 响应用户输入的是一个线程, 后台程序处理是另外的线程

## 选型方案

1. 需要频繁创建销毁的优先用线程(进程的创建和销毁开销过大)这种原则最常见的应用就是 Web 服务器了, 来一个连接建立一个线程,
   断了就销毁线程, 要是用进程, 创建和销毁的代价是很难承受的
2. 需要进行大量计算的优先使用线程(CPU频繁切换), 所谓大量计算, 当然就是要耗费很多 CPU, 切换频繁了, 这种情况下线程是最合适的,
   这种原则最常见的是图像处理、算法处理
3. 强相关的处理用线程, 弱相关的处理用进程
    1. 一般的 Server 需要完成如下任务: 消息收发、消息处理, “消息收发”和“消息处理”就是弱相关的任务,
       而“消息处理”里面可能又分为“消息解码”、“业务处理”
    2. 这两个任务相对来说相关性就要强多了, 因此“消息收发”和“消息处理”可以分进程设计, “消息解码”、“业务处理”可以分线程设计
4. 可能要扩展到多机分布的用进程, 多核分布的用线程

# 作为架构师, 常见系统性能级要烂诵于心

1. nginx 负载均衡 5w 左右
2. memcached 读性能 5w 左右
3. redis 读性能 10w 左右
4. kafka 百万吞吐
5. zookeeper 写入读取 2w 以上
6. rocketmq 10w
7. http 请求访问量大概在 2w 左右
8. mysql 单机 QPS 7k-8k
9. ElasticSearch 1 TB QPS 读2500左右, 写性能是 1000 左右
10. 业务系统如果复杂度差异很大, 每秒 500 都是很高了

# 事务+幂等

1. 上游唯一id, 下游用唯一id做幂等 + 分布式锁防并发
2. 数据库做幂等, 必须有事务的保护

# 为什么三次、四次

第三次握手时为了防止已失效的连接请求报文段有传送到 B, 因而产生错误, B 向 A 发送确认报文后, A 判断是否正确, 可能会有 syn
攻击四挥, 主动方等着被动方发完给个 FIN, 被动方不知道要结束还会静静地维持连接

# 四次挥手为什么 TIME_WAIT 是 2MSL

MSL 是报文在网络中最长生存时间, 不同的系统中可能不同发出 ack+ 收到 fin = 2msl, 为了让所有的包都消失 1msl 没有收到 ack 或者
fin 会超时重传

# http 和 rpc 区别

1. http 1.x 有几个明显问题, 不支持长链接, http 头大但是只能用小数据, 浪费流量, 只能用 json 序列化, 文本传输, 只支持
   request-response 通信模型, 缺点是无用字段太多, 主流的
2. 大部分 rpc 支持 stream, 序列化+传输+反序列化, dubbo是二进制序列化, netty ip多路复用支持异步通信模型, 性能上比http好,
   用于服务端推送, 视频码流,
   服务端客户端异步场景, etcd 的 watch 由于使用 grpc 支持服务端推送, api更加友好, 性能好, 比如req-res必须等list完整才相应,
   stream从第一个元素加载完成客户端开始处理, 可以提前cancel请求

## rpc

是思想, 实现有 http,dubbo,thrift,grpc, 本质区别在于序列化协议不一样, 和 header body 大小不一样, http1.1最常用也最慢, 因为
json 序列化协议可读性好但是慢, header 无用东西占用太大, 所以出来了 dubbo, thrift 自定义序列化协议, 减少 header body 大小,
性能好。后来 http2 出来了, 做的事情也是这两种, pb 协议和 header 有索引压缩同时多路复用减少连接, 所以本质上就是协议和大小
看中生态和性能和前景就是 gRpc, 因为 pb 协议和 http2 都是行业标准

rpc 框架的好处是可以帮你生成大量代码, 不用重头撸, 最大的差别是数据的压缩率

rpc 就是调用别的进程的函数, 一般都是走网络调用。网络调用有很多方式, 一般是基于tcp。tcp之上有很多协议, http是其中一种, pb
和thrift是另外两种比较出名的tcp之上的协议, grpc是把数据依照pb协议编码然后利用http2协议进行传输的一套技术方案的统称,
为了方便使用提供了一套IDL和多种语言的代码生成工具

# https

1. ssl 三次握手, 主要是以非对称加密形式完成对称加密的密钥的传输, 客户端传输浏览器支持的加密方式, 服务端选其中一个证书形式返回客户端,
   在采用 SSL 后, HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。也就是说 HTTP 加上加密处理和认证以及完整性保护后即是
   HTTPS。
   https 采用了非对称加密+对称加密结合的方式来工作(主要是 ssl 来做), 因为非对称加密速度慢, 所以先利用非对称加密来传输对称加密的密钥,
   然后再使用对称加密的方式传输。在 ssl 建立了安全的通信线路后就可以在这条线路上进行 http 通信了
2. Client 发起一个 HTTPS (比如https: //juejin.im/user/5a9a9cdcf265da238b7d771c)的请求, Client 知道需要连接 Server 的 443
   端口
3. Server 把事先配置好的公钥证书 (public key certificate) 返回给客户端
4. Client 验证公钥证书:比如是否在有效期内, 证书的用途是不是匹配 Client 请求的站点, 是不是在 CRL 吊销列表里面,
   它的上一级证书是否有效, 这是一个递归的过程, 直到验证到根证书(操作系统内置的 Root 证书或者 Client 内置的 Root 证书),
   如果验证通过则继续, 不通过则显示警告信息
5. Client 使用伪随机数生成器生成加密所使用的对称密钥, 然后用证书的公钥加密这个对称密钥, 发给Server
6. Server 使用自己的私钥(private key)解密这个消息, 得到对称密钥, 至此, Client 和 Server 双方都持有了相同的对称密钥
7. Server 使用对称密钥加密明文内容 A, 发送给 Client
8. Client 使用对称密钥解密响应的密文, 得到明文内容 A
9. Client 再次发起 HTTPS 的请求, 使用对称密钥加密请求的明文内容B, 然后 Server 使用对称密钥解密密文, 得到明文内容B

# 数字证书

1. 数字证书是一个经证书授权中心数字签名的包含公钥拥有者信息以及公钥的文件
2. 最简单的证书包含一个公钥、名称以及证书授权中心的数字签名, 数字证书还有一个重要的特征就是只在特定的时间段内有效
3. 数字证书的生成是这样的: 服务端将自己的公钥及相关信息交给证书机构, 机构使用其私钥加密服务端的公钥及相关信息,
4. 而客户端(浏览器) 在安装的时候就自带了权威数字证书机构的公钥, 可以利用证书机构的公钥从数字证书中提取出服务器端的公钥

# 输入一个 URL,会发生什么

1. 浏览器的地址栏输入 URL 并按下回车
2. 浏览器查找当前 URL 是否存在缓存, 并比较缓存是否过期
3. DNS 解析 URL 对应的 IP (比如 127.0.0.1 yyy.baidu.com) 根据后者对应 127.0.0.1
4. 根据 IP 建立 TCP 连接(三次握手)
5. HTTP 发起请求
6. 服务器处理请求, 浏览器接收 HTTP 响应
7. 渲染页面, 构建 DOM 树
8. 关闭 TCP 连接(四次挥手)

# http请求过程

1. 对网址进行 DNS 域名解析, 得到对应的 IP 地址
2. 根据 IP 找到对应的服务器, 发起 TCP 的三次握手
3. 建立 TCP 连接后发起 HTTP 请求
4. 服务器响应 HTTP 请求, 浏览器得到 html 代码
5. 浏览器解析 html 代码, 请求 html 中包含其他资源地址(如 js、css 图片等)
6. 浏览器对页面进行渲染呈现给用户

# HTTP2.0 和 HTTP1.X 相比的新特性

1. 新的二进制格式 (Binary Format) HTTP1.x 的解析是基于文本
2. 多路复用 (MultiPlexing) 即连接共享, 即每一个 request 都是是用作连接共享机制的, 一个 request 对应一个 id, 这样一个连接上可以有多个
   request, 每个连接的 request 可以随机的混杂在一起
4. 服务端推送(server push), 同 SPDY 一样, HTTP 2.0 也具有 server push 功能

# 机器核数配置

48核 128G 100M 带宽
监控 k8s 中 java 进程的内存使用, 达到阈值之后 hpa 扩容


8 核 64G 服务器 10M


我们是小企业 就在本地 56台服务器 比云便宜, 毕竟配置要求高, 维护很简单, 没那么麻烦, 我管着56台服务器还有120台网络设备, 每天不是很忙

离线备份和在线备份都是自动化运行, 硬件有问题直接报警手机短信和邮件就来了, 所有设备都是双机热备主主模式, 5秒内重切换完毕, 虚拟化是vm的ft, 一天物理机故障另一台就自动漂移过去, 在线备份是软件自动备份到本地, 然后有 自动发给备份储存服务器, 离线定时联网, 然后抓取数据, 备份完毕自动断网

OA。聊天服务器。hr服务器。加起来得8台吧, 这些还只是业务服务器不包括加密服务器 域控。日志。储存 那些服务器, 主要我们数据都在本地, 我说的这些不包括20台监控储存, 还有安防
聊天软件也是买的本地部署, 服务器 130t 是最低配, 储存是 192t*12 台

自建idc 到时候客户出问题丢数据赔钱的是自己, 每天全量备份,  机柜, 电控, 交换机, 路由器, 线材等等, 而且你是人工+电费+网费+硬件折损, 你要是想用高配可以直接租机房机器或者托管

硬件维护 故障冗余 灾难恢复 等等都很麻烦并且不便宜 机房的价格也不低 去机房的成本也不低（硬件维护你必须去）
云服务器最大的开销是带宽, 行宽带和独立 ip 费用, 电费也是一大块输出, 只能说短期还是云服务器合适, 时间久了硬件又过时了, 死循环

对外部业务一台2核4g的服务器, 每年能支撑 10 多个商家, 几十万订单

130t 48核*2 1t  十几万, 二手搞一台。8000多块钱。跑几十个虚拟机。 用六七年没问题。 云服务器一年好几万

80核 CPU、256G 内存, 16TB 1w多, 云贵 10倍多, 云上的200tb 基本上没有数据丢失的可能, 你自己要做的同样的安全级别, 会比云上还贵

一台服务器大概 4-5 万, 一主一备, 一台服务器每年电费 6000-8000

自建事情太多了, 机房要搞机架、服务器、散热、ups 等, 硬件层面要考虑硬盘、内存、网络硬件的监控维护, 网络要搞搭企业网络、路由器交换机、防火墙, 系统层面要os安装升级、安全防护等, 服务层面要考虑各种中间件的可靠性(数据库、MQ、缓存等)、应用的高可用(比如要自建k8s)。每个方面都要专门的人维护, 这样就导致硬件方面可能成本小, 但是人力成本很高

数据敏感自己弄, 算力上云

32g 内存, 16核 cpu, 100M独享带宽

# 微服务架构
很多微服务架构, 其实就是加个nacos和gateway, 数据库还是一套, 分布式事务尽量不上（补偿就够了）, 本质上与单体差异不大
总共10万用户, 每天在线几千人, 网页请求10万, 2核的阿里云服务器, cpu的使用率才 1.5%到2.5% 之间

# 离线和在线
面试是一回事, 实际很多公司玩不起实时计算那一套

# ETL
读取数据, 数据处理, sql boy, 业务逻辑复杂实时是算不准的, 离线数据对不上, 只有大屏之类的在用

## 星型模式和雪花模式

1. 雪花模式: 维度表进一步拆成子维度表
2. 星型模式: 事实表(每一行代表特定时间里发生的事件)
3. 列存储: 查询速度快, 列式插入必须始终更新所有列, 第一个排序键压缩效果最强, 压缩列, 写入难, 可以用LSM树, 先内存后磁盘
