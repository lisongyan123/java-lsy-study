# 消息队列在项目中的作用

1. 解耦
2. 异步
3. 日志

# 两种 mq 方案选择

1. kafka: 单机 topic 多, 消息发送性能会严重降低, 批处理差
2. RocketMQ: 单机支持最高 5w 个队列, 实时性好
3. sendfile 直接向网络套接字发送数据包, mmap是需要通过映射访问内存拿数据
    1. kafka 写用 mmap (内存映射), 读用 senfile
    2. rmq 读写都用 mmap (内存映射), 追求极致顺序写一个 commitlog, 所以要加锁
4. 采用诸如 zookeeper 这种追求强一致性框架, 如果出现网络分区, 严重的时候 zookeeper 并不能提供注册与路由寻址方式,
   会影响整个集群对外提供服务, 严重违背分布式架构的高可用设计理念

# 案例场景:

1. 用户注册要发短信, 使用 mq, 在原来的服务系统基础上增加 mq 服务
2. 广播消费: 派单服务将订单指派给司机的时候, 发送一个推送消息, 用广播消费的模式实现, 推送服务保存司机的 channel 和编号,
   每一台机器接收到消息, 判断内存是否存在该机器的 channel
3. 对于订单采用激进的方案: 先写缓存再发送到 mq 来写数据库, 并判断有无乱序, 同一个订单号发送到同一个 partition, 开启一个守护任务,
   定时轮询当前正在进行的订单, 当缓存与数据库不一致的时候, 修复数据, 并发送警报
4. 短信服务, 用户注册验证码, 营销短信, 单发, 群发等等

# 消息队列总结

1. mq 不丢失一般都要考虑发送不丢, 中间件挂了不丢, 接受消息不丢
2. kafka 发送有同步阻塞保证消息一定发成功, 但性能低, 一般都用异步加个 callback, 可以将消息写到数据库设个状态为已发送,
   回调后将消息设成发送成功
3. kafka 肯定要设 cluster, topic 肯定要分片副本。当消息到达 broker, kafka 采用写入 OS cache 再异步刷盘, 同时还会将消息同步到副本
   要保证不丢, 主和副本磁盘都要写入成功
4. 所以有刷盘配置和 ack 机制, 刷盘配置每条消息都刷, ack 配置 all 保证所有机器写入成功, 但这样性能极大降低, 估计没人会这么配,
   接受消息有个 ack 机制, 改成消息消费成功才手工 ack, 并做好幂等。kafka-sink 端实现二阶段提交接口保证事物

# 协议和标准

与消息队列相关的协议和标准有 JMS、AMQP、MQTT 和 OpenMessaging

# 消息重复的情况必然存在

在 MQTT 协议中, 给出了三种传递消息时能够提供的服务质量标准, 这三种服务质量从低到高依次是:

1. At most once: 至多一次。消息在传递时, 最多会被送达一次。换一个说法就是, 没什么消息可靠性保证,
   允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用, 比如每分钟上报一次机房温度数据, 可以接受数据少量丢失
2. At least once: 至少一次。消息在传递时, 至少会被送达一次。也就是说, 不允许丢消息, 但是允许有少量重复消息出现
3. Exactly once: 恰好一次。消息在传递时, 只会被送达一次, 不允许丢失也不允许重复, 这个是最高的等级

# 序列化

Google 的 Protobuf、Kryo、Hessian 等, 像 JSON、XML 这些标准的数据格式, 也可以作为一种序列化实现来使用, 权衡几样因素

1. 序列化后的数据最好是易于人类阅读的
2. 实现的复杂度是否足够低
3. 序列化和反序列化的速度越快越好
4. 序列化后的信息密度越大越好, 也就是说, 同样的一个结构化数据, 序列化之后占用的存储空间越小越好

# gc

GC 算法大多采用的是“标记 - 清除”算法或是它的变种算法, 这种算法分为标记和清除两个阶段

1. 标记阶段: 从 GC Root 开始, 你可以简单地把 GC Root 理解为程序入口的那个对象, 标记所有可达的对象, 因为程序中所有在用的对象一定都会被这个
   GC Root 对象直接或者间接引用
2. 清除阶段: 遍历所有对象, 找出所有没有标记的对象。这些没有标记的对象都是可以被回收的, 清除这些对象, 释放对应的内存即可

这个算法有一个最大问题就是, 在执行标记和清除过程中, 必须把进程暂停, 否则计算的结果就是不准确的。这也就是为什么发生垃圾回收的时候,
我们的程序会卡死的原因。后续产生了许多变种的算法, 这些算法更加复杂, 可以减少一些进程暂停的时间, 但都不能完全避免暂停进程

最有效的方法就是, 优化你的代码中处理请求的业务逻辑, 尽量少的创建一次性对象, 特别是占用内存较大的对象。比如说, 我们可以把收到请求的
Request 对象在业务流程中一直传递下去, 而不是每执行一个步骤, 就创建一个内容和 Request 对象差不多的新对象, 如果可能的话,
使用更大内存的服务器, 也可以非常有效地缓解这个问题

# 扩容

要保证 Consumer 和分区数量相等, 不然没有实际效果

# 有序

不需要全局有序, 只要局部有序就可以了, 传递账户流水记录的时候, 保证每个账户流水有序就可以了, 不同账户之间流水记录不需要保证顺序,
发送端采用账户 ID 为 key, 一致性哈希算法算出队列编号

# 单个队列并行消费

1. 队列改成数组, 随机访问, OFFSET 定位消费的消息
2. mq 不主动删除消息, 设置过期时间, 超过过期时间不能重新消费, 保留最大可设置天数
3. 客户端没有返回 ACK 就重发

# 为什么要存算分离

1. 现有的流计算平台, 包括 Storm、Flink 和 Spark, 它们的节点都是无状态的纯计算节点, 是没有数据存储能力的。 现在的流计算平台,
   很难做大量数据的聚合, 并且在数据可靠性保证、数据一致性、故障恢复等方面, 也做得不太好
2. 消息队列正好相反, 它很好地保证了数据的可靠性、一致性, 但是 Broker 只具备存储能力, 没有计算的功能, 数据流进去什么样,
   流出来还是什么样

# 顺序

1. broker 创建一个单分区的 topic
2. producer 将所有数据发送到多个分区 topic 某一个分区, 消费端消费指定分区
3. flink 消费 mq, 按照时间戳开创, 1s 一个窗口, 一个窗口内数据无顺序, 窗口函数排序, 窗口间排序, 迟到数据会被丢弃
4. 状态机控制, 没到处理的前置条件, 收到了扔到延迟队列中
5. 京东某个项目可以保证多个队列之间有序

# 数据中转:

1. KV 存储 HBase
2. 搜索 ElasticSearch
3. 流式处理 Storm、Spark、Samza
4. 实时数据库 OpenTSDB

# kafka 为什么快

- 顺序写: 读写都会寻址->写入, 其中寻址是一个“机械动作”, 它是最耗时的。 收到消息后 Kafka 会把数据插入到文件末尾。写入数据顺序写入, 磁盘顺序读或写的速度400M/s, 能够发挥磁盘最大的速度,随机读写,
  磁盘速度慢的时候十几到几百 K/s。partition就是一个文件, 以此实现顺序写入 Consumer 从 broker 读取数据时, 因为自带了偏移量, 接着上次读取的位置继续读, 以此实现顺序读
- 分区存储: 来利用内存提高I/O效率
- mmap: 进程像读写硬盘一样读写内存, 把数据先放到内核空间的内存中,非堆内存开辟一块内存空间, 和 OS 内核空间的一块内存进行映射
- zero copy:数据直接在内核完成输入和输出, 不需要拷贝到用户空间再写出去。kafka 数据写入磁盘前, 数据先写到进程的内存空间。
- 稀疏索引


# 推拉模式:
另一方面消费者也可以设定自身逻辑决定是否拉数据

# 零拷贝:

1. producer把消息发送给kafka, 落地用到 mmp, 内存映射
2. kafka把消息发送给消费者时, 用到 sendfile 叫零拷贝

# 消息积压:

kafka如果一个topic有多个消费者组, 其中一个消费者组宕机, 造成消息挤压, 会对另外一个消费者组有影响？ 看美团文章, 消息进度差距过大, 消息不在一个文件里面了, kafka会抖动,
为了赶进度会污染页缓存导致另一个消费者吞吐量降低 一般线上数据保存 7 天就删除了, 如果一直不消费超过了数据的保存期限, 数据就丢失了
