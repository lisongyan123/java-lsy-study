# k8s历史
很久以前每个系统要独立申请独立的硬件资源, 由于各系统高峰和地址资源利用情况不一样, 闲置的资源像内存碎片一样无法使用, 资源分配僵化, 全局硬件使用率不高。
google 大佬认为资源应该是弹性, 放在一个池子, 想用就拿走, 用完拿回来。
问题在于: 怎么保证资源隔离, 各系统共享资源不能互相影响, 程序运行环境千千万, 如何统一打包便于灵活部署, 机器的资源池怎么管理, 更高级的资源分配策略, 怎么用配置文件和命令
为了同步和高可用, 开源界山寨了 zookeeper, 复杂系统的监控山寨了 prometheus

# 有状态服务部署到 k8s
1. 服务数据完全分离即可, 数据挂载到本机目录下

# DevOps
CI（Continuous Integration）, 持续集成。开发完成代码开发后, 能自动地进行代码检查、单元测试、打包部署到测试环境, 进行集成测试, 跑自动化测试用例

CD（Continuous Deploy）, 持续部署。代码测试通过后, 能自动部署到类生产环境中进行集成测试, 测试通过后再进行小流量的灰度验证, 验证通过后代码就达到线上发布的要求了, 就可以把代码自动部署到线上

这就是 docker 做不到的地方, docker 以前就是没法做到 ingress 的功能, 所以要通过nginx或者haproxy去做路由
nginx 是物理级别的, ingress 是 k8s 提供的一个内部路由组建
所以只用 docker 的话, 做负载的话需要大量的运维去处理 nginx 路由的配置

然后 K8S 里面可以通过 namespace 做物理隔离, 比如在资源不够的情况下, 各个部门都要用, 开发部门用开发部的, 大数据用大数据的

说的直白点, pod里面装的是docker, docker里面跑的是你的应用