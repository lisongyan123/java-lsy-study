# 滚动翻页的话

每次都要带上当前页的最大id来最为过率条件, 但是最大id无法实现跳页
不要用mysql的自增id, 如果分表的话, 可以用分布式id, 就是美团的Leaf

# 自增 ID 问题

![](../中间件技术/大数据和分布式/images/自增ID问题.png)

并发导致生成重复自增 ID

# UUID

**例子:** 550e8400-e29b-41d4-a716-446655440000, 按照开放软件基金会(OSF)制定的标准计算, 用到了以太网卡地址、纳秒级时间、芯片ID码和许多可能的数字, 每台机器 MAC 地址和网卡不一样,
可以区分不同机器

1. 优点: 本地生成, 没有网络消耗
2. 缺点: UUID 太长, 不容易存储, 根据 MAC 地址生成的不安全, 做 mysql 主键, 36 位不符合要求, 官方要求主键越短越好, 无序性会引起数据位置频繁变动, 影响性能

# Snowflake

![](images/snowflake.png)

1. 41-bit 的时间可表示, (1L<<41) / (1000L*3600*24*365) = 69 年的时间
2. 10-bit 分别表示 1024台机器
3. 12 个自增序列号
4. QPS 约为 409.6w/

**优点** 不依赖数据库, 性能高, 整个ID都是趋势递增  
**缺点** 依赖机器时钟, 始终回拨会导致法号重复或者不可用状态  

## 雪花算法生成 ID 重复问题

1. workerID 通过构造方法传入, 用机器的唯一 key 做, 最多支持 1024 台服务器
2. 容器化部署的话, 可能存在扩容的时候, 发现不同, 就会累加, 超过 1024, 位置会左移, 影响时间戳, 导致谁能从重复的 ID
3. 1000ms 和 1001ms、worked = 0配置, 可以生成重复 ID
![](../中间件技术/大数据和分布式/images/snowflake重复ID.png)

# 数据库自增ID

1. 强制依赖数据库可用性, 但是主从切换数据不一致可能导致重复发号, 对数据库读写性能有要求
2. 水平扩展比较困难, ID 无法单调递增, 对于业务需求不是很重要

# Leaf 方案

# Leaf-segment数据库方案

利用 proxy server 批量获取, 每次获取一个 segment 号段的值, 用完再去数据库获取新的号段, 减轻数据库的压力, 业务以 biz-tag 来区分, max_id 表示 biz_tag 目前所分配的 ID 号段最大值,
step 表示每次分配号段长度, 扩容后只要对 biz_tag分库分表即可

```sql
+-------------+--------------+------+-----+-------------------+-----------------------------+
| Field       | Type         | Null | Key | Default           | Extra                       |
+-------------+--------------+------+-----+-------------------+-----------------------------+
| biz_tag     | varchar(128) | NO   | PRI |                   |                             |
| max_id      | bigint(20)   | NO   |     | 1                 |                             |
| step        | int(11)      | NO   |     | NULL              |                             |
| desc        | varchar(256) | YES  |     | NULL              |                             |
| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on
update CURRENT_TIMESTAMP |
    +-------------+--------------+------+-----+-------------------+-----------------------------+
```

1000 个号段都被消耗完了再去读写一次数据库

![](../中间件技术/大数据和分布式/images/leaf.png)

## 优点

1. Leaf服务可以很方便的线性扩展, 性能完全能够支撑大多数业务场景
2. ID号码是趋势递增的 8 byte的 64 位数字, 满足上述数据库存储的主键要求
3. 容灾性高: Leaf 服务内部有号段缓存, 即使 DB 宕机, 短时间内Leaf仍能正常对外提供服务
4. 可以自定义 max_id 的大小, 非常方便业务从原有的 ID 方式上迁移过来

## 缺点

TP 999 数据波动大, 用完之后还会卡在数据库

## 双 buffer 优化

号段临界点的 ID 下发时间取决于下次从 DB 取回号段的时间, 这段时间号段没有取回, 导致线程阻塞, 如果请求 DB 的网络和 DB 性能不稳定会卡住

做到无阻塞, 号段消费到某个点就异步把下一个号段加载到内存, 而不要等待用尽了采取更新

## leaf 高可用

一主两从, 分机房部署, Master 和 Slave 之间半同步, 使用 DBProxy 做主从切换, 在极端情况下会造成数据不一致, 如果想保证强一致可以用类 Paxos 算法

## 使用场景

生成趋势递增的 ID, 不适合订单 ID, 比如竟对在两天中午 12 点下单, 通过订单 ID 算出一天的订单量

# Leaf-snowflake方案

![](../中间件技术/大数据和分布式/images/美团的Leaf_snowflake.png)

1. 使用 Zookeeper 持久顺序节点配置对 snowflake 节点配置 workID
2. leaf_forever 检查自己是否注册, 注册了就取回自己的 workId
3. 没注册就在父节点下面创建持久顺序节点, 创建成功后取回顺序号当作自己的 workerID
   ![](../中间件技术/大数据和分布式/images/leaf-snowflake.png)

## 时钟回拨问题

![](../中间件技术/大数据和分布式/images/时钟回拨.png)

因为强制依赖时钟, 机器工作时 NTP 同步也会造成秒级别的回退, 时钟回拨的时候直接不提供服务直接返回 ERROR_CODE, 等待时钟追上即可