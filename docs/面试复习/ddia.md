# 现状

很多应用是数据密集型, 而非计算密集型, 更大的问题来自于数据量、数据复杂度、数据变更速度, 许多程序都需要

- 存储数据, 以便自己或其他应用程序之后能再次找到(数据库, 即 databases)
- 记住开销昂贵操作的结果, 加快读取速度(缓存, 即 caches)
- 允许用户按关键字搜索数据, 或以各种方式对数据进行过滤(搜索索引, 即 search indexes)
- 向其他进程发送消息, 进行异步处理(流处理, 即 stream processing)
- 定期处理累积的大批量数据(批处理, 即 batch processing)

# CAP 定理

1. 因网络问题导致某些副本与其他副本断开连接, 这些副本掉线不能处理请求, 所有服务不可用
2. 不需要线性一致性的话, 某副本即使与其他副本断开连接, 也可以独立处理请求, 比如多主复制, 这肯定不是线性一致性
3. 不要求线性一致性, 更能忍受网络故障

# 软件系统很重要的三种问题

1. 可靠性(Reliability) : 系统在困境(硬件故障、软件故障、人为错误) 中仍可正常工作
    1. 硬件故障: 增加单个硬件冗余度, 云平台优先考虑灵活性和弹性, 而非单机可靠性
    2. 软件故障: 仔细考虑假设和交互; 彻底的测试; 重启; 监控
    3. 人为错误: 最小化犯错机会的方式设计系统; 容易犯错的地方解耦; 测试; 监控; 培训
2. 可扩展性(Scalability) : 有合理的办法应对系统的增长(数据量、流量、复杂性)
    1. 批处理: 关注吞吐量
    2. 实时系统: 关注相应时间
    3. 流处理: 在线离线之间, 近实时操作
    4. 客户端响应时间(非服务端)很重要: 比如头部阻塞、网络延迟
    5. 系统响应时间最好用百分位点, 实践中的百分位点, 用滑动窗口进行统计(比如 10 分钟) 进行统计, 对列表进行排序
3. 应对负载方法
    1. 纵向扩展: 转向更强大的机器
    2. 横向扩展: 将负载分布到多台小机器上
    3. 弹性系统: 检测到负载增加时自动增加计算资源
    4. 跨多台机器部署无状态服务比较简单, 但是把带状态的数据系统从单节点变成分布式配置则可能引入许多额外复杂度。因此, 应该尽量将数据库放在单个节点上。
4. 可维护性(Maintainability) : 许多不同的人在不同的生命周期, 都能高效地在系统上工作
5. 分布式系统: 可伸缩性、容错和低延迟(数据放在用户较近的地方)

# 可维护性

1. 可运维性: 便于运维团队保持系统平稳运行, 尽量自动化
2. 简单性: 从系统中消除尽可能多的复杂度, 使新工程师也能轻松理解系统, 抽象性
3. 可演化性(可扩展性、可塑性): 使工程师在未来能轻松地对系统进行更改, 当需求变化时为新应用场景做适配

# 索引

1. 保存额外的元数据作为路标, 帮助查找数据
2. 主数据衍生的附加结构
3. 允许添加和删除索引, 影响查询性能
4. 维护额外的结构会产生开销, 特别在写入

# hash 索引

**字典用散列表或者 hash table 实现, Bitcask 就是这么做的, 非常适合每个键的值频繁更新的情况**

**如果一直追加文件, 怎么防止用完磁盘空间?**

1. 日志分为特定大小的段, 日志增长到特定尺寸关闭当前段, 并写入新的段文件, 对段压缩
   ![](images/hash索引.png)
2. 压缩意味着在日志中丢弃重复的键, 只保留每个键的最近更新
   ![](images/段合并.png)
3. 多个段压缩到一起, 段都是upsert, 合并的段写入新的文件, 冻结段的合并和压缩可在后台线程中完成, 读写请求在新的段, 删除旧的段, 每个段都有自己的内存散列表, 键映射到文件偏移量, 查找键要一次遍历所有的散列表
4. 奔溃恢复
    1. 数据库重新启动, 内存散列映射丢失
    2. 根据日志文件重新恢复每个段的 hash 映射, 段很大的时候浪费时间
5. 写操作是以严格顺序附件到日志, 一般只有一个写线程, 读操作可以多线程读

# LSM 树和 SSTable: 树上内存, 树外落盘

1. MemTable: 是在内存中的数据结构, 用于保存最近更新的数据, 会按照Key有序地组织这些数据, LSM树对于具体如何组织有序地组织数据并没有明确的数据结构定义。
2. 因为数据暂时保存在内存中, 内存不可靠, 通过WAL(Write-ahead logging, 预写式日志)的方式来保证数据的可靠性, 写入的日志不是有序的, 因为不需要, 目的只是为了奔溃后恢复内存
3. Immutable MemTable: 当 MemTable达到一定大小后, 会转化成Immutable MemTable。Immutable
   MemTable是将转MemTable变为SSTable的一种中间状态。写操作由新的MemTable处理, 在转存过程中不阻塞数据更新操作
4. SSTable: 有序键值对集合, 是LSM树组在磁盘中的数据结构。为了加快SSTable的读取, 可以通过建立key的索引以及布隆过滤器来加快key的查找
5. 当MemTable达到一定大小flush到持久化存储变成SSTable后, 在不同的SSTable中, 可能存在相同Key的记录, 当然最新的那条记录才是准确的, 合并都是保留最新的值
6. 不再需要保存内存中所有键的索引。因为是有序的, 可以先查找出键所处的范围, 然后就找到这个键所在的偏移量的区间
7. memtable 有顺序, 可以是多种数据结构, 比如 hbase 是跳跃表, 也可以是红黑树, AVL 树

## 性能优化

1. 布隆过滤器, 防止查询段踏空
2. Hbase 使用大小分层
3. LevelDB 和 RocksDB 使用平坦压缩
4. Cassandra 同时支持

# B 树

1. B 树将数据库分解为固定大小的块和页面, 一次只能读写一个页面
2. 每个页面都可以使用地址或位置来标识, 存在磁盘

## 过程

1. 更新: 搜索包含该键的叶页, 更改页的值, 该页写磁盘原来的位置
2. 插入: 找到其范围包含新键的页面, 添加该页面, 页面不够容纳新键, 就分散到两个半满页面
3. 并发访问: 锁存器, 保护树的数据结构来完成
4. 每个键对应索引中的一个位置, 属于一对一, 通过键值范围上使用锁来实现的, 锁可以直接连接到树

# 数据分析

|     属性     |      事务处理系统 OLTP       |      分析系统 OLAP       |
| :----------: | :--------------------------: | :----------------------: |
| 主要读取模式 |    查询少量记录, 按键读取    |    在大批量记录上聚合    |
| 主要写入模式 |   随机访问, 写入要求低延时   | 批量导入(ETL) 或者事件流  |
|   主要用户   |    终端用户, 通过 Web 应用     | 内部数据分析师, 用于决策支持 |
|  处理的数据  | 数据的最新状态(当前时间点)  |   随时间推移的历史事件   |
|  数据集尺寸  |           GB ~ TB            |         TB ~ PB          |

# 数据仓库

1. OLTP 对业务运作很重要, 通常会要求`高可用`和`低延迟`
2. 数仓允许分析人员查询内容不影响 OLTP 操作
3. 包含共识各种 OLTP 系统中所有只读数据副本
4. OLTP 数据库中提取数据(实时或者离线), 转换成适合分析的模式, 清理并加载到数据仓库中, 数据存入仓库路的过程是 ETL
5. 查询比较少, 磁盘贷款往往是瓶颈, 列式存储是解决方案

## 星型模式和雪花模式

1. 雪花模式: 维度表进一步拆成子维度表
2. 星型模式: 事实表(每一行代表特定时间里发生的事件)
3. 列存储: 查询速度快, 列式插入必须始终更新所有列, 第一个排序键压缩效果最强, 压缩列, 写入难, 可以用LSM树, 先内存后磁盘

# 编码

## json 和 xml 和 csv

1. `XML` 和 `CSV` 不能区分数字和字符串。`JSON` 不能区分整数和浮点数
2. 不支持二进制, 通过base64解决

## Thrift 与 Protocol Buffers

Protocol Buffers, Thrift 都使用模式来描述二进制编码格式

# 复制

1. 同步复制: 主从保持一致, 从库没有响应, 主库就无法写入, 主库必须阻止所有的写入, 等待副本再次可用
2. 异步复制: 新主库和老主库不一致, 与缓存也不一致, 就会导致私有数据泄漏到错误的用户手中
3. 脑裂: 如果两个主库都可以写操作, 没有冲突解决机制, 数据就会丢失或者损坏, 安全防范措施是关闭其中一个主节点

# 读写一致性

1. 时间戳: 客户端记住最近一次写入的时间戳, 从库提供查询, 保证时间戳变更传播到了本从库, 否则从另外的从库读 (时间戳可以是逻辑时间戳, 如日志序列号；或者要有准确的时间同步),
   多个设备更新时间戳很困难, 不同设备路由到不同数据中心
2. 单调读: 第一次请求有评论, 第二次请求评论消失, 确保用户每次都是从同一个副本读
3. 一致性前缀: 分片数据库的问题, 任何因果相关的数据写入相同分区

# 多主复制

1. 单主复制是常用做法
2. 多个领导者的复制：允许多个节点接受写入, 复制仍然是转发给所有其他节点。每个领导者也是其他领导者的追随者

## 多主复制使用场景

1. 单个数据中心多主没意义
    1. 单主每个写入都穿过互联网, 进入主库所在的数据中心, 增大写入时间
    2. 主库数据中心发生故障, 必须让另一个数据中心追随者成为主领导者
    3. 单主配置对网络连接问题非常敏感, 因为写是同步的
2. 异地多活, 每个数据中心内部使用常规的主从复制, 数据中心之间, 每个数据中心的主库都会将其更改复制到其他数据中心的主库中
    1. 多主配置, 每个写操作可以在本地数据中心进行处理, 其他数据中心异步复制
    2. 每个数据中心都可以独立于其他数据中心继续运行, 若发生故障的数据中心归队
    3. 数据中心之间的网络需要通过公共互联网, 不如数据中心之内的本地网络可靠
    4. 异步复制的多主配置更好地承受网络问题, 应用程序断网后仍能继续工作, 在所有设备上的日历副本之间同步时, 存在异步的多主复制过程
    5. 两个数据中心可能会修改相同的内容, 写冲突被絮解决, 比如两个用户同时修改标题
    6. 比较危险, 必须避免
3. 避免冲突的策略
    1. 确保特定记录的写入通过同一个 Leader , 就不会有冲突, 数据中心如果故障, 需要把流量重新路由
    2. 多主没有明确顺序, 给每一个写入唯一ID(一个时间戳, 一个长的随机数, 一个UUID或者一个键和值的哈希), 挑选最终值作为胜利者
    3. 每个副本分配唯一 id, id编号高的具有更高的优先级, 可能导致数据丢失
    4. 某种方式将值合并
    5. 以一种显示数据结构保留所有信息, 解决冲突方法来提示用户
4. 自定义冲突逻辑
    1. 写时执行: 数据库系统检测到复制更改日志中存在冲突, 就会调用冲突处理程序
    2. 读时执行: 当检测到冲突时, 所有冲突写入被存储, 下一次读取数据时, 会将这些多个版本的数据返回给应用程序, 应用程序可能会提示用户或自动解决冲突, 并将结果写回数据库
5. 自动冲突解决
    1. 无冲突复制数据类型: 可以由多个用户同时编辑的集合, 有序列表, 计数器等的一系列数据结构, 它们以合理的方式自动解决冲突
    2. 可合并的持久数据结构: 显式跟踪历史记录, 类似于Git版本控制系统, 并使用三向合并功能
    3. 可执行的转换: Etherpad 和Google Docs 等合作编辑应用背后的冲突解决算法
6. 多主复制拓扑: 写入从一个节点传播到另一个节点的通信路径, 防止无限循环
   ![](images/复制拓扑.png)
    1. 一个节点故障, 可能中断其他节点之间的复制消息流
    2. 全部到全部拓扑: 网络问题导致消息顺序错乱, 利用版本向量技术解决

## 无主复制

1. 所有副本都接受来自客户端的写入, 一个副本下线, 重启后数据是落后的, 客户端同时请求多个副本, 根据版本号确定最新值

# 检测并发写入

- 方案一: 为每个写入附加一个时间戳, 挑选最 “最近” 的最大时间戳, 并丢弃具有较早时间戳的任何写入
- 缺点: 以持久性为代价, 如果同一个 Key 有多个并发写入, 即使它们报告给客户端的都是成功(因为它们被写入 w 个副本), 也只有一个写入将存活, 而其他写入将被静默丢弃, 甚至可能会删除不是并发的写入, 如果丢失数据不可接受,
  那么最后写入胜利是个很烂的选择
- 场景: 唯一安全的方法：每一个键只写入一次, 然后视为不变, 避免并发更新

- 方案二: 此前发生的关系和并发, 确定两个操作是否是并发的, 还是先后关系
- 场景: 两个并发操作, 有版本号的, 为每个键保留一个版本号, 每次写入键值都增加版本号, 客户端写入先查键, 写入时包含之前`未覆盖`的最新的版本号, 并且将所有值合在一起, 服务器接收到具有版本号的写入时, 覆盖版本号的所有值,
  必须用更高的版本号保存所有值
- 旧版本数据会被覆盖, 不会丢失任何值
- 原理: 当一个写入包含前一次读取的版本号时, 可以知道写入是基于之前那种状态, 换句话说就是服务器是串行的, MVCC机制
  ![](images/发生关系先后.png)

# 合并同时写入的值

场景: 1. 多领导冲突 2. 根据版本号或者时间戳最后写入胜利, 会丢数据

## 版本向量: 解决无助副本同步的问题

1. 每个副本、每个主键都定义一个版本号
2. 每个副本处理写入时, 增加自己的版本号, 跟踪从其他副本看到的版本号
3. 取最大的版本号
4. 所有副本的版本号集合称为版本向量

# 分区、分片

1. 可伸缩性
2. 大数据集分布在多个磁盘, 查询负载分布在多个处理器上
3. 大型、复杂的查询会跨越多个节点并行处理, 带来了新的困难, 分区不均匀的话, 数据倾斜严重, 分区效率下降很多, 所有负载压在一个分区上, 瓶颈都在这一个节点上, 造成热点
4. 避免热点? 随机分配节点, 读特定值不知道在哪个节点上, 必须并行查所有节点
5. 根据键的散列分区, 公平分配键, 有时候被称为一致性 hash, 不利于范围查询, 可以做组合索引, 有效的检索特定用户在某个时间间隔内按照时间戳排序的所有更新
    1. 缺点是每次查数都要到各个分区去读, 然后合并
    2. 还要记录哪些键要被分割
6. 根据键的范围分区 如 hbase

## 二级索引

对关系数据库很重要, 也是 es 的基石

![](images/二级索引分区.png)

1. 基于文档的分区: 二手车网站, 需要在颜色和厂商的次级索引过滤, 可以做二级索引, 查询时要查询所有分区, 合并所有结果返回。查询分区数据库方法有时候被称为分散/聚集 (mongo、es、cassandra)
   ![](images/关键词分区.png)
2. 基于关键词的分区： 对范围扫描非常有用
    1. 优点: 读取速度快
    2. 缺点: 但是写入速度慢且可能影响索引的多个分区, 需要跨分区的分布式事务, 对全局二级索引的更新通常是异步的

## 分区与复制

1. 每条记录有同一个分区, 分区仍有不同的节点, 提高容错
2. Leader 一个节点, follower 其他节点

## 分区重平衡

1. 重平衡之后, 负载应该在集群中的节点之间公平共享
2. 平衡发生时, 数据可以享受读写权限
3. 节点之间只移动必须的数据, 方便快速平衡, 减少网络和磁盘 IO 负载

### 重平衡策略

1. `hash 取模`, 重平衡变得昂贵了, 最符合一致性哈希的原始定义
   ![](images/固定数量分区.png) 
2. `固定数量的分区`(Elasticsearch 的 reindex), 创建比节点更多的分区, 比如 4 变 5, 取模等于 4 的放到 node 4, 避免牵一发而动全身的感觉
3. `动态分区`, 采用关键字区间分区, 边界问题可能导致数据倾泻到一个分区中
    1. 按键的范围分区(hbase分区文件的传输通过HDFS), 分区超过一定大小(HBase 默认是 10GB), 会被分成两个分区, 每个分区占一半数据, 数据被删除缩小到某个阈值下, 可以合并, 但是空的数据库只有一个分区,
       所有写入都必须单个节点处理
    2. 解决: mongo 和 hbase 可以在空数据库配置初始分区, 预分割
    3. Cassandra 是分区数与节点成正比, 每个节点有固定数量分区
    4. 缺点:
        1. 结果不可预测
        2. 大量数据移动代价大, 网络负载、节点负载中
        3. 遇到自动故障检测, 判断节点负载高, 开始重新平衡会导致结果更糟
4. 请求路由: 确定客户发出请求时, 知道要连接哪个节点进行读取
    1. 轮询
    2. 加权轮询
    3. 客户端分配
5. 怎么知道分区-节点负载均衡的变化?
    1. 共识协议, 比如 zookeeper, 集群中添加或者删除节点, zookeeper 会通知路由层。kafka、hbase 用 zookeeper, mongodb 用自己的配置服务器
    2. gossip protocol, cassandra, 增加了复杂度, 避免对 zookeeper 这样的外部协调服务依赖
    3. 不自动重新平衡 elasticsearch 的 reindex

# 网络问题

- 请求可能已经丢失(可能有人拔掉了网线)
- 请求可能正在排队, 稍后将交付(也许网络或接收方过载)
- 分布式系统通过超时来容错, 单无法判断是网络失效还是节点失效
- 远程节点可能已经失效(可能是崩溃或关机)
- 远程节点可能暂时停止了响应(可能会遇到长时间的垃圾回收暂停), 但稍后会再次响应
- 远程节点可能已经处理了请求, 但是网络上的响应已经丢失(可能是网络交换机配置错误)
- 远程节点可能已经处理了请求, 但是响应已经被延迟, 并且稍后将被传递(可能是网络或者你自己的机器过载)

# 故障检测

1. 负载平衡器需要停止向已死亡的节点转发请求, 移出轮询列表
2. 当前部署的技术不允许我们对网络的延迟或可靠性作出任何保证
3. 在一段较长的时期内、在多台机器上测量网络往返时间的分布, 以确定延迟的预期变化, 不是固定的常量超时时间, 而是连续测量响应时间及其变化来自动调整超时时间
4. 部署的技术不允许我们对网络的延迟或可靠性作出任何保证, 必须假设网络拥塞, 排队和无限的延迟总是会发生

# 不可靠时钟

1. 分布式系统中, 时间很棘手, 因为通信不是即时的, 网络延迟, 并且不知道晚了多少时间, 导致不知道事件发生的顺序
2. 每个机器都有自己的时钟, 是个硬件设备: 石英晶体振荡器。但是该硬件不可靠, 需要通过服务器进行同步
3. 并发写入不知道 A 和 B 两个线程谁先写进来的
4. 避免方法: 逻辑时钟基于递增计数器, 测量事件的相对顺序
5. spanner 使用跨数据中心的快照隔离, 时间置信区间
6. 分布式系统没有共享内存, 不像单机一样可以直接实现线程安全

# 拜占庭容错

1. 幂等可以由客户端传来一个版本号, 保证幂等
2. 但是 1 仍然不可靠, 用户可以恶意假冒客户端, 某个节点可能会撒谎, 在不信任的环境中达成共识
3. 仅仅发生在航空航天环境或者多个参与组织的系统中, 一般系统不需要考虑这个, 代价高

# 为什么不考虑拜占庭

1. web 系统是中心化的, 服务器决定了客户端行为
2. 软件 bug 可能是拜占庭错误, 但是拜占庭算法要求 2/3 节点正常
3. 传统机制(认证、访问控制、加密、防火墙)是低于攻击者主要保护措施

# 一致性

1. 大多数复制的数据库都采用最终一致性, 不向数据库写入数据, 等待一段时间, 最终所有的读取请求都会返回相同值

## 分布式一致性模型

1. 比最终一致性更强的模型
2. 事务隔离是避免由于同时执行事务而导致的竞争状态, 分布式一致性在面对延迟和故障时如何协调副本间的状态

## 线性一致性

1. 数据库可以提供只有一个副本的假象, 每个客户端都由相同数据视图, 线性一致性(linearizability) , 也称为原子一致性(atomic consistency) , 强一致性(strong consistency) ,
   立即一致性(immediate consistency)  或外部一致性(external consistency)
2. 只要一个客户端成功写完写操作, 所有客户端都能从数据库读取各个看见的值, 新鲜度保证
3. 与串行化的区别: 线性一致性是读取和写入寄存器的新鲜度保证, 串行化是事务之间是穿行的

### 线性一致性依赖条件

1. 锁定和领导选举
    1. 多个节点同时启动, 尝试获取锁, 拿到的就是领导者
    2. zookeeper 和 etcd 之类的协调服务通常用于实现分布式锁和领导者选举, 一致性算法以容错的方式实现线性一致性
    3. 分布式锁在分布式数据库更多的粒度级别上使用
2. 约束和唯一性保证
    1. 用户名和邮箱唯一, 文件路径和名词不能重复
    2. 关系型数据库主键需要线性一致性
3. 跨信道的时序依赖
    1. 上传图片后压缩, 分两个服务, 文件存储和消息队列传递压缩指令
    2. 消息队列如果太快, 就找不到图片或者压缩了老的图片  
       ![](images/消息压缩.png)

### 实现线性一致性系统

1. 单主复制(可能线性一致性)
    1. 从主库或者已经同步的从库更新数据, 那就是线性一致性
    2. 从主库读取, 节点误以为自己是领导
    3. 异步复制, 可能故障切换时丢失已提交的写入, 违反了持久性和线性一致性
2. 共识算法(线性一致) : zookeeper、etcd
    1. 防脑裂
    2. 旧副本的措施
3. 多主复制(非线性一致性)
    1. 多主程序复制到系统都是非线性一致性, 节点间异步复制, 可能产生写入冲突, 缺少单一数据副本导致
4. 无主复制(也许不是线性一致性)
    1. 根据最后胜利者冲突解决方法确定是非线性一致性, 始终偏差不能保证时钟与顺序一致
    2. 法定人数也不保证会线性一致性

### 线性一致性和网络延迟

1. 线性一致性的系统惊人的少, 甚至多核 CPU 的内存都不是线性一致性(除非用了内存屏障或者围栏), 内存缓冲区和存储缓冲区与内存之间是异步的
2. 许多分布式数据库为了提高性能舍弃线性一致性
3. 找不到更高效的线性一致性存储实现? Attiya 和 Welch 证明想要线性一致性读写请求的响应时间与网络延迟不确定性成正比
4. 更快的线性一致性算法不存在, 更弱的一致性模块可以快更多

# 顺序保证

1. 复制日志中确定写入顺序, 不存在一个领导者, 并发操作可能导致冲突
2. 可串行化, 关于事务表现像某种先后顺序, 以串行化顺序执行事务实现, 防止序列化冲突
3. 时间戳和时钟是另一种将顺序引入无序世界的尝试

## 序列号

1. 因果关系的序列号: 每个操作都有一个唯一的序列号, A 在 B 之前, 那么 A 有更小的序列号
2. 非因果关系序列号:
    1. 每个节点生成独立的序列号, 第一个生成奇数, 第二个生成偶数
    2. 日历时钟时间戳附加到每个操作, 要具有足够高的分辨率, 提供一个操作全序关系
    3. 预先分配序列号区块, 节点 A 要求序列号 1-1000 区块所有权, 节点 B 要求序列号 1001-2000 所有权, 每个节点可以独立分配所属区块中的序列号
    4. 生成序列号与因果不一致
3. 兰伯特时间戳:
    1. 节点计数器 + 节点 ID (counter, node ID)
    2. 优先选计数器大的, 计数器相同, 取节点 ID 大的
    3. 客户端 A 从节点2 接收计数器值 5, 然后将最大值 5 发送到节点1 。此时, 节点1 的计数器仅为 1, 但是它立即前移至 5, 所以下一个操作的计数器的值为 6
       ![](images/兰伯特时间戳.png)
    4. 缺点是节点之间还不能完美同步
4. 全序广播:
    1. 解决4 的问题, zookeeper 和 etcd 实现了全序广播, 通过一个日志文件来实现 CAS 操作
    2. 每个消息代表一次数据库写入, 每个副本按照相同顺序处理相同写入, 副本间保证一致性
    3. 后续消息送达, 节点不允许追溯以前的消息了
    4. 通过创建日志, 追加写入日志, 所有节点必须以相同顺序传递相同消息, 所有节点都可以读取日志, 看到相同消息序列
    5. 全序广播对于实现提供房屋令牌的锁服务也有用, 锁的请求作为一条消息追加日志末尾, 序列号当作防护令牌使用且单调递增, 在 zookeeper 里是 zxid
    6. 与线性一致性区别是, 全序广播是异步的, 可以保证写先行一直, 单不保证读线性一致
    7. 举例: 用户名放重复, 往日志写消息, 读日志, 检查是我的消息就操作, 否则中止
    8. 线性一致读可以先写, 写成功了表示我可以读还有读取的时间点(etcd), 根据日志的位置把该位置前所有消息都传达过来再执行读取 (zookeeper), 也可从同步更新的副本读取(链式复制)
5. 线性一致性实现全序广播
    1. 线性一致性寄存器存储一个整数, 有一个原子自增返回或者原子 CAS 操作
    2. 通过全序广播发送消息对寄存器自增返回, 作为序列号加消息里面, 将消息发送 到所有节点, 节点按照序列号存储消息
6. 线性一致性的 CAS 寄存器与全序广播等价于共识问题, 解决其中一个问题, 可以把他转化为其他问题解决方案

# 分布式事务

1. 分布式事务的名声毁誉参半, 尤其是那些通过两阶段提交实现的。
2. 一方面, 它被视作提供了一个难以实现的重要的安全性保证；
3. 另一方面, 它们因为导致运维问题, 造成性能下降, 做出超过能力范围的承诺而饱受批评。
4. 许多云服务由于其导致的运维问题, 而选择不实现分布式事务。
5. mysql 分布式事务比单节点事务慢 10 倍以上

# MapReduce 和分布式文件系统

1. 读写的是 HDFS 等分布式文件系统
2. 基于无共享的原则
3. 每台机器运行了一个守护进程, 对外暴露网络服务
4. 容忍机器故障, 文件块会被复制到多台机器上
5. 可伸缩性很好：上万台机器, PB 级别存储

## MapReduce 作业执行

![](images/mapreduce.png)

1. 每个分区都被写入 Mapper 程序的本地磁盘
2. Reducer 从 Mapper 开始获取输出文件
3. 从 Mapper 向 Reducer 复制分区数据, 这一整个过程被称为混洗(shuffle)

## MapReduce 特点

1. 没有索引的概念
2. 查询只能全表扫描
3. 通常需要计算大量记录的聚合
4. 一般是用来处理所有用户的数据, 而非某个特定用户的数据
5. 批量处理最好再单台机器上进行, 为待处理的每条记录发随机访问的网络请求太慢了, 最好是获取用户数据库的数据仓库, 将它和用户行为日志放入 HDFS ,MapReduce 将相关记录集中到一起处理
6. MapReduce处理了所有的网络通信, 因此它也避免了让应用代码去担心部分故障, 一个节点崩溃, MapReduce 不影响逻辑情况下能够透明的重试失败的任务
7. 人类容错: 代码错误或者输出损坏, 回滚代码重跑一遍, 输出就会修正
8. Map 或者 Reduce 任务失败, MapReduce 框架将自动重新调度, 在同样的输入上再次运行, 重试几次就行, 因为输入不可变, 保证了数据安全

## MapReduce 与 分布式数据库对比

1. 分布式数据库专注于在一组机器上并行执行分析SQL查询
2. MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序, map 输入 <KEY, VALUE>, 经过 map 计算后输出一对 <KEY, VALUE>, 将相同的 Key 合并, 形成 <KEY, VALUE集合> 输入 reduce, 经计算输出 0 或 n个<KEY, VALUE>

## 数据倾斜

1. 热键: 单个 key 映射大量数据, 相同 key 的数据放在同一个地方, 导致分区出现 big key
2. 倾斜: 单个Reducer中收集与某个角色相关的所有活动, 比如微博明星官宣, 可能导致严重的偏斜
3. MapReduce 必须等待所有的 Mapper 和 Reducer 完成才行
4. 数据倾斜必然是计算

### 解决数据倾斜

1. 先运行一个抽样作业( Sampling Job) 来确定哪些键是热键
2. join 执行时, 一侧 Mapper 会将热键的关联记录随机(相对于传统MapReduce基于键散列的确定性方法)发送到几个Reducer之一
3. 热键相关的记录需要被复制到所有处理该键的 Reducer 上
4. 将处理热键工作分散多个 Reducer 上, 但是要将 join 的另一侧输入记录复制到多个 Reducer 上

# 批处理工作流的输出

1. 在数据库查询的场景中, 我们将事务处理( OLTP) 与分析两种目的区分开来
2. OLTP查询通常根据键查找少量记录, 使用索引, 并将其呈现给用户( 比如在网页上) 
3. 分析查询通常会扫描大量记录, 执行分组与聚合, 输出通常有着报告的形式：显示某个指标随时间变化的图表, 或按照某种排位取前10项, 或将一些数字细化为子类

# Map Reduce 建立索引

1. 为 ES 建立索引
2. Mapper 根据需要对文档集合进行分区
3. 每个 Reducer 构建该分区的索引, 并将索引文件写入分布式文件系统

## 索引更新怎么办

1. 定期重跑整个索引工作流, 完成后用新的索引文件批量替换以前的索引文件
2. 增量建立索引, 需要索引中添加, 删除或更新文档

# 怎么输出到 OLTP 数据库呢

1. 一条条插入, 每条记录发起一个网络请求, 比批量处理吞吐量慢, 可能压垮数据库
2. 在批处理作业内创建一个全新的数据库, 并将其作为文件写入分布式文件系统中作业的输出目录, 数据文件一旦写入就是不可变的, 可以批量加载到处理只读查询的服务器中, 文件只读, 数据结构简单

# 数据流引擎 Spark、 Flink

数据流引擎的共同点：把整个工作流作为单个作业来处理, 而不是把它分解为独立的子作业, 通过网络将一个函数的输出复制到另一个函数的输入

## 容错

1. Spark: Spark使用弹性分布式数据集( RDD, Resilient Distributed Dataset)  的抽象来跟踪数据的谱系
2. Flink: Flink对算子状态存档, 允许恢复运行在执行过程中遇到错误的算子
3. 遇到不确定性的计算(比如哈希表的迭代、随机数), 解决方案通常是杀死下游算子, 然后再重跑新数据, 比如随机数设定固定的种子

# 流处理

一个事件由生产者生成一次, 进而由多个消费者进行处理, 流式系统中, 相关的事件通常被聚合为一个 topic 或者 stream

## 流存储

1. 生产者把事件放数据库, 然后消费者定期轮询, 检查上次运行的新事件, 这个方案和批处理没区别了
2. 消息系统: 生产者和消费者用 tcp 连接信道传递
3. 生产者速度大于消费者速度怎么办
    1. 丢掉消息
    2. 消息放入队列, 基于日志的方法
    3. 施加背压
4. 落后太多, 监控消费者落后的日志头部距离, 产生警报, 即使落后太多也只是一个消费者的问题
5. 节点崩溃或者脱机, 那就写入磁盘进行复制
6. 吞吐量超过了单个磁盘怎么办? 对日志分区, 不同分区可以托管在不同的机器上, 分区内完全有序, 跨分区没有顺序保证

## 消费者偏移量

1. 判断消息是否已经被处理, 小于偏移的都已经被处理, 否则都会被处理
2. 定期记录消费者偏移量
3. 即使消费者失效了, 也会被指派到其他节点, 并从最后的偏移量开始消费消息, 没有记录偏移量重启后消息被处理两次

## 磁盘使用空间

1. 为了防止磁盘被使用殆尽, 日志被分割成段, 不时地将旧段删除或者移动到归档存储
2. 慢消费者跟不上消息生产的速率落后太多, 错过被删除的消息
3. 日志实现了有限大小的缓冲区, 环形缓冲区或者循环缓冲区

## 变更数据捕获 (change data capture CDC)

1. 观察写入数据库的所有变更, 提取并且转换为可以复制到其它系统形式的过程
2. flink cdc、领英的 databus、Maxwell 的 debezium、kafka connect将广泛的数据库系统变更数据捕获与 kafka 集成
3. 原理是, 一段是 Leader , 另一端充当 follower, 基于日志保证顺序
4. 异步, 但是有延迟

## 日志压缩

保留每个键值的最新值, 去除历史的重复内容

## 事件溯源

1. 对所有应用状态的变更存储为变更事件日志
2. 事件存储是 upsert , 更新与删除不允许
3. 随着应用的演化更有意义, 更容易理解事情发生的原因来帮助调试的进行, 有利于防止 bug
4. 用户关心系统当前状态, 不是变更历史
5. 事件往往表示用户操作的意图, 而不是因为操作而发生的状态更新机制, 需要用到完整的历史事件重构最新状态

## 流处理场景

长期以来, 流处理一直用于监控目的, 如果某个事件发生, 组织希望能得到警报。

1. 信用卡欺诈检测系统
2. 股票交易系统
3. 机器状态监控
4. 军事情报系统
5. 对监控摄像头进行人脸识别和嫌犯追踪

## 流分析

1. 测量某个事件的速率
2. 滚动计算一段时间窗口内某个值的平均值
3. 当前系统统计值和之前时间区间值对比(同比)
4. 概率算法, Bloom filter, HyperLogLog 用于基数估计以及各种百分比估计算法, 产出近似的结果, 但比起精确算法的优点是内存使用要少得多
5. 应用框架: Apache Storm, Spark Streaming, Flink, Concord, Samza和Kafka Streams, Google Cloud Dataflow 和 Azure Stream Analytics

# 时间戳
## 时间戳来源
1. 事件发生的机器
2. 不可靠时钟

## 校正不准确时钟, 忽略网络传输时间可以用 2 和 3 估算时钟偏移 
1. 事件发生的时间, 取决于设备时钟
2. 事件发送往服务器的时间, 取决于设备时钟
3. 事件被服务器接收的时间, 取决于服务器时钟

## 窗口的类型
1. **滚动窗口(Tumbling Window)**
1 min, 10:03:00和10:03:59之间的事件会被分组到一个窗口中, 10:04:00和10:04:59之间的事件被分组到下一个窗口
2. **跳动窗口(Hopping Window)**
1 min, 跳动步长 5 min 的窗口, 10:03:00至10:07:59之间的事件, 而下一个窗口将覆盖10:04:00至10:08:59之间的事件
3. **滑动窗口(Sliding Window)**
5分钟的滑动窗口应当覆盖10:03:39和10:08:12的事件, 因为它们相距不超过5分钟, 不会把这两个事件分组到同一个窗口中, 因为它们使用固定的边界, 通过维护一个按时间排序的事件缓冲区, 并不断从窗口中移除过期的旧事件, 可以实现滑动窗口
4. **会话窗口(Session window)**
会话窗口没有固定的持续时间, 将同一用户出现时间相近的所有事件分组在一起, 而当用户一段时间没有活动时, 如果30分钟内没有事件窗口结束, 比如 token 最大在线时间

## 流连接
### 流-流
1. 流处理器需要维护状态
2. 按会话ID索引最近一小时内发生的所有事件, 添加索引
3. 流处理器也会检查另一个索引是否有具有相同会话ID的事件到达

### 流-表
1. 用户事件和用户档案数据库相关联
2. 做法一: 每个活动事件, 在数据库中查询一次用户 ID, 速度慢
3. 做法二: 数据库副本加载到流处理器中。类似于 Map 侧连接中把数据集拷贝到内存中。

### 表-表
1. 维护推特时间线
2. 维护了一个连接了两个表(推文与关注)的物化视图, 推文事件流(发送与删除)和关注关系事件流(关注与取消关注)

### 时间依赖性
如果跨越流的事件顺序是未定的, 则连接会变为不确定性的, 这意味着你在同样输入上重跑相同的作业未必会得到相同的结果, 数据仓库被称为缓慢变化的维度(slowly changing dimension, SCD)通常通过对特定版本的记录使用唯一的标识符来解决

每次状态数据变化都携带标识符, 查询标记以下使用哪个版本的标识符, 让连接变成确定性的。比如 Version1 改成 Version 2, 查询时候要按照 Version 1 来查询

`缺点`: 数据库无法进行日志压缩, 所有记录版本都会保留

# 容错
**批处理** 重试, 因为输入是不变的, 恰好一次语义（exactly-once semantics）, 尽管等效一次（effectively-once）
**流处理** 
1. 微批次: 将流分解成小块(Spark Streaming)
2. 存档点: 定期生成状态的滚动存档点并将其写入持久存储 (Flink), 如果流算子崩溃, 它可以从最近的存档点重启, 并丢弃从最近检查点到崩溃之间的所有输出, 存档点会由消息流中的壁障(barrier)触发, 类似于微批次之间的边界

## 精确一致性
微批次与存档点方法提供了与批处理一样的恰好一次语义, 但是, 只要输出离开流处理器（例如, 写入数据库, 向外部消息代理发送消息, 或发送电子邮件）, 框架就无法抛弃失败批次的输出了。在这种情况下, 重启失败任务会导致外部副作用发生两次, 只有微批次或存档点不足以阻止这一问题, 必须注意幂等处理

**解决方案**
1. 分布式事务
2. 幂等性

## 失败重试
1. 将状态保存在远程数据存储中, 并进行复制。很慢。 
2. 另一种方法是在流处理器本地保存状态, 并定期复制。然后当流处理器从故障中恢复时, 新任务可以读取状态副本, 恢复处理而不丢失数据。 flink 捕获快照 复制到 HDFS